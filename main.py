import os
from utils.pdf_parser import extract_text_from_pdf, chunk_text
from utils.embedding_generator import EmbeddingGenerator
from utils.search_engine import SemanticSearchEngine

def load_pdfs(pdf_dir):
    all_chunks = []
    all_files = []
    for file in os.listdir(pdf_dir):
        if file.endswith(".pdf"):
            path = os.path.join(pdf_dir, file)
            print(f"ğŸ“„ Processing {file}...")
            text = extract_text_from_pdf(path)
            chunks = chunk_text(text)
            all_chunks.append((file, chunks))
    return all_chunks

def main():
    pdf_dir = "pdfs"  # Folder where you put input PDFs
    query = input("ğŸ” Enter your search query: ")

    print("ğŸ“– Loading and processing PDFs...")
    all_chunks = load_pdfs(pdf_dir)

    print("ğŸ§  Generating embeddings...")
    embedder = EmbeddingGenerator()
    search_engine = SemanticSearchEngine(dimension=384)  # 384 for all-MiniLM-L6-v2

    for file_name, chunks in all_chunks:
        embeddings = embedder.generate(chunks)
        search_engine.add(embeddings, chunks, file_name)

    print("ğŸ” Searching FAISS index...")
    query_embedding = embedder.generate([query])[0]
    results = search_engine.search(query_embedding, top_k=5)

    print("\nğŸ“Œ Top Results:")
    for i, res in enumerate(results, 1):
        print(f"\nğŸ”¹ Result {i}")
        print(f"ğŸ“„ File: {res['file']}")
        print(f"ğŸ§¾ Text: {res['text'][:300]}...")
        print(f"ğŸ“Š Similarity Score (lower = more similar): {res['score']:.4f}")

if __name__ == "__main__":
    main()
